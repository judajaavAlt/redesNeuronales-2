{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00ccaad",
   "metadata": {},
   "source": [
    "# Modelo RNN Con Memoria (LSTM)\n",
    "\n",
    "En este cuaderno se implementa una Red Neuronal Recurrente con memoria a largo plazo (LSTM) para la clasificación de texto.\n",
    "Las redes LSTM están diseñadas para evitar el problema del desvanecimiento del gradiente y capturar dependencias a largo plazo en secuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52657f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610dd7",
   "metadata": {},
   "source": [
    "## Carga y Preprocesamiento de Datos\n",
    "\n",
    "Se cargan los archivos `.npy` y se preparan los tensores.\n",
    "Al igual que en el modelo simple, redimensionamos la entrada a `(N, 1, 384)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564b3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1200000\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "train_X = np.load('train_all.npy')\n",
    "train_y = np.load('train_labels.npy')\n",
    "valid_X = np.load('valid_all.npy')\n",
    "valid_y = np.load('valid_labels.npy')\n",
    "test_X = np.load('test_all.npy')\n",
    "test_y = np.load('test_labels.npy')\n",
    "\n",
    "# Convertir a tensores y redimensionar\n",
    "X_train_tensor = torch.tensor(train_X, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_train_tensor = torch.tensor(train_y - 1, dtype=torch.long).to(device)\n",
    "\n",
    "X_valid_tensor = torch.tensor(valid_X, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_valid_tensor = torch.tensor(valid_y - 1, dtype=torch.long).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(test_X, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_test_tensor = torch.tensor(test_y - 1, dtype=torch.long).to(device)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de9e1c",
   "metadata": {},
   "source": [
    "## Definición del Modelo LSTM\n",
    "\n",
    "Se utiliza `nn.LSTM` en lugar de `nn.RNN`.\n",
    "- **Input Size**: 384.\n",
    "- **Hidden Size**: 128.\n",
    "- **Output Size**: 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d753c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(384, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        # out shape: (batch, seq_len, hidden_size)\n",
    "        # h_n, c_n shapes: (num_layers, batch, hidden_size)\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Tomamos la salida del último paso de tiempo\n",
    "        last_out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(last_out)\n",
    "        return out\n",
    "\n",
    "# Instanciar el modelo\n",
    "input_size = 384\n",
    "hidden_size = 128\n",
    "output_size = 5\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaae62a",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Entrenamiento del modelo LSTM con `CrossEntropyLoss` y `Adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f71b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.0908, Train Acc: 52.04%, Valid Loss: 1.0669, Valid Acc: 53.36%\n",
      "Epoch [2/10], Train Loss: 1.0573, Train Acc: 53.47%, Valid Loss: 1.0568, Valid Acc: 53.79%\n",
      "Epoch [2/10], Train Loss: 1.0573, Train Acc: 53.47%, Valid Loss: 1.0568, Valid Acc: 53.79%\n",
      "Epoch [3/10], Train Loss: 1.0447, Train Acc: 54.02%, Valid Loss: 1.0489, Valid Acc: 54.14%\n",
      "Epoch [3/10], Train Loss: 1.0447, Train Acc: 54.02%, Valid Loss: 1.0489, Valid Acc: 54.14%\n",
      "Epoch [4/10], Train Loss: 1.0358, Train Acc: 54.43%, Valid Loss: 1.0485, Valid Acc: 53.90%\n",
      "Epoch [4/10], Train Loss: 1.0358, Train Acc: 54.43%, Valid Loss: 1.0485, Valid Acc: 53.90%\n",
      "Epoch [5/10], Train Loss: 1.0290, Train Acc: 54.80%, Valid Loss: 1.0485, Valid Acc: 53.80%\n",
      "Epoch [5/10], Train Loss: 1.0290, Train Acc: 54.80%, Valid Loss: 1.0485, Valid Acc: 53.80%\n",
      "Epoch [6/10], Train Loss: 1.0233, Train Acc: 55.03%, Valid Loss: 1.0480, Valid Acc: 53.89%\n",
      "Epoch [6/10], Train Loss: 1.0233, Train Acc: 55.03%, Valid Loss: 1.0480, Valid Acc: 53.89%\n",
      "Epoch [7/10], Train Loss: 1.0185, Train Acc: 55.30%, Valid Loss: 1.0487, Valid Acc: 53.88%\n",
      "Epoch [7/10], Train Loss: 1.0185, Train Acc: 55.30%, Valid Loss: 1.0487, Valid Acc: 53.88%\n",
      "Epoch [8/10], Train Loss: 1.0145, Train Acc: 55.43%, Valid Loss: 1.0507, Valid Acc: 53.79%\n",
      "Epoch [8/10], Train Loss: 1.0145, Train Acc: 55.43%, Valid Loss: 1.0507, Valid Acc: 53.79%\n",
      "Epoch [9/10], Train Loss: 1.0108, Train Acc: 55.63%, Valid Loss: 1.0499, Valid Acc: 53.75%\n",
      "Epoch [9/10], Train Loss: 1.0108, Train Acc: 55.63%, Valid Loss: 1.0499, Valid Acc: 53.75%\n",
      "Epoch [10/10], Train Loss: 1.0073, Train Acc: 55.81%, Valid Loss: 1.0506, Valid Acc: 53.60%\n",
      "Epoch [10/10], Train Loss: 1.0073, Train Acc: 55.81%, Valid Loss: 1.0506, Valid Acc: 53.60%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += y_batch.size(0)\n",
    "        correct_train += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # Validación\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in valid_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_valid += y_batch.size(0)\n",
    "            correct_valid += (predicted == y_batch).sum().item()\n",
    "            \n",
    "    valid_acc = 100 * correct_valid / total_valid\n",
    "    avg_valid_loss = valid_loss / len(valid_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Valid Loss: {avg_valid_loss:.4f}, Valid Acc: {valid_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39760ca",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Evaluación del modelo LSTM en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82f8edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 53.35%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 1       0.62      0.71      0.66      6000\n",
      "     Clase 2       0.44      0.46      0.45      6000\n",
      "     Clase 3       0.43      0.37      0.40      6000\n",
      "     Clase 4       0.48      0.41      0.44      6000\n",
      "     Clase 5       0.64      0.72      0.68      6000\n",
      "\n",
      "    accuracy                           0.53     30000\n",
      "   macro avg       0.52      0.53      0.53     30000\n",
      "weighted avg       0.52      0.53      0.53     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Clase 1', 'Clase 2', 'Clase 3', 'Clase 4', 'Clase 5']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
